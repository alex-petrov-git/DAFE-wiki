---
tags:
  - мм_тема
  - мм_метод
---
[[Математические методы планирования и интерпретации эксперимента]]  
Prev Theme: [[Перебор и недобор факторов регрессии]]  
Next Theme: [[Цифровое сглаживание и дифференцирование]]  

---
В прошлой теме мы поняли к чему приводит недобор и перебор факторов. В этой теме мы рассмотрим критерии выбора значимых факторов регрессии. Если есть две модели регрессии (учитывающие разные наборы факторов $x'$ и $x''$) то лучшей будет считаться та, для которой выбранный критерий меньше (на одном и том же наборе данных $X$). Особенности выбора критерия разберем позднее.
### Критерий Акаике (AIC)
Критерий AIC вычисляется по формуле:  $$
\text{AIC} = 2k - 2 \ln \hat{L},
$$где:
- $k$ — число факторов модели,
- $\hat{L}$ — оценка функции правдоподобия.  
В случае КЛНР критерий можно записать в другом виде
$$
\text{AIC} = 2k + n \ln(\hat{\sigma}^2_{ммп}).
$$
где $n$ — количество строк матрицы $X$ (количество наборов данных).
### Скорректированный AIC (AICc)
При малом объёме выборки $n$ (особенно если $n / k < 40$) критерий AIC требует корректировки:  
$$
\text{AICc} = \text{AIC} + \frac{2k(k+1)}{n-k-1},
$$
Скорректированный AIC более строг в штрафе за сложность модели (количество факторов $k$).  
### Байесовский информационный критерий (BIC)
AIC выбирает более сложные модели, поэтому был предложен BIC, который вычисляется по формуле: 
$$
\text{BIC} = 2k \ln n - 2 \ln \hat{L},
$$
BIC выбирает более простые модели (с меньшим $k$), особенно при большом объёме данных $n$.
### Сравнение критериев

| Критерий | Формула                              | Штраф за сложность            |
| -------- | ------------------------------------ | ----------------------------- |
| **AIC**  | $2k - 2\ln \hat{L}$                  | Пропорционален $k$            |
| **AICc** | $\text{AIC} + \frac{2k(k+1)}{n-k-1}$ | Усиленный штраф при малых $n$ |
| **BIC**  | $2k \ln n - 2\ln \hat{L}$            | Зависит от $k \ln n$          |
### Замечания к критериям
1. Если среди конкурирующих моделей есть истинная, то асимптотически (при $n\to \infty$) BIC определяет истинную с вероятностью 1, а AIC с вероятностью <1.
2. Если истинной модели нет, то асимптотически AIC выбирает лучше, чем BIC.
3. При конечном n AIC лучше чем BIC.